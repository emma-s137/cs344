{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfbQl9/ZXNsb7Xcd+SyuLn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emma-s137/cs344/blob/master/homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frrSn6j9OicN",
        "colab_type": "text"
      },
      "source": [
        "Homework 3 for CS 344 \n",
        "04-07-20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cPis6UfgPkj",
        "colab_type": "text"
      },
      "source": [
        "1. Compute the following values using the restaurant example.\n",
        "\n",
        "The *information gain* provided by using the price attribute as the root of the decision tree. Is it more or less valuable than the type or patrons attributes computed in class?\n",
        "\n",
        "\n",
        "Using data from AIMA, Section 18.3\n",
        "\n",
        "Gain (P) = Entropy(D) - Remainder (P)\n",
        "\n",
        "Entropy (Domain) = 1.0\n",
        "Remainder (Price?) = 7/12 * Entropy(\\$) + 2/12 * Entropy(\\$$) + 3/12 * Entropy(\\$$$)\n",
        "\n",
        "Entropy (\\$) = -((4/7) log (4/7) + (3/7) * log(3/7)) * (7/12) = 0.5747\n",
        "\n",
        "Entropy (\\$$) = -((2/2) log (2/2) + 0 = 0\n",
        "\n",
        "Entropy (\\$$$) = -((2/3) log (2/3) + (1/3) * log(1/3)) * (3/12) = 0.22957\n",
        "\n",
        "\n",
        "Remainder (Price?) = 0.5747 + 0 + 0.22957 = 0.8043\n",
        "\n",
        "\n",
        "Gain (H) = 1 - 0.8043\n",
        "\n",
        "Gain (Price?) = 0.1957\n",
        "\n",
        "Patrons is a more effective question with an information gain of 0.54."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjLxj9J-rCHi",
        "colab_type": "text"
      },
      "source": [
        "2. In class, we attempted to create by hand a neural network that computes the XOR function. If this was possible, see if you can simplify the network we built. Consider relaxing the conventions of densely-connected, sequential layers. If it was not possible, give a full explanation why it canâ€™t be done.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbtIzzdq6JbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A simplified version of the XOR function using a neural network can be seen in Xor.png.\n",
        "This image was found at http://www.mnemstudio.org/neural-networks-multilayer-perceptrons.htm\n",
        "\n",
        "\n",
        "The image shows the answer being solved with 4 nodes. 2 input nodes, one hidden node (the and), and one output node (the or).\n",
        "Both inputs have a weight of 1 to the AND. The AND node has threshold of 1.5 to be activated. The edge weight from the AND to the OR is -2.\n",
        "The edge weight from the inputs to OR are also 1. The OR node then has an activation threshold of 0.5. This can be achieved with either\n",
        "of the input nodes receiving a true value, but not the other."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYMe8E1B6S_6",
        "colab_type": "text"
      },
      "source": [
        "3. Use Python/NumPy/Pandas/Keras to load and manipulate the Boston Housing Dataset as follows.\n",
        "\n",
        "a. Compute the dimensions of the data structures. Include code to print these values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YfPRRq56cd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "382983cb-a10a-4567-c597-da65c2956266"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "(train_set, train_y), (test_set, test_y) = boston_housing.load_data()\n",
        "\n",
        "def print_structures():\n",
        "    print(\n",
        "        'training set \\\n",
        "            \\n\\tcount: {} \\\n",
        "            \\n\\tdimensions: {} \\\n",
        "            \\n\\tshape: {} \\\n",
        "            \\n\\tdata type: {} \\\n",
        "            \\n\\ttrain shape: {} \\n\\n'.format(\n",
        "                len(train_set),\n",
        "                train_set.ndim,\n",
        "                train_set.shape,\n",
        "                train_set.dtype,\n",
        "                train_y.shape,\n",
        "        ),\n",
        "        'testing set \\\n",
        "            \\n\\tcount: {} \\\n",
        "            \\n\\tdimensions: {} \\\n",
        "            \\n\\tshape: {} \\\n",
        "            \\n\\ttest shape: {} \\\n",
        "            \\n\\tdata type: {} \\n'.format(\n",
        "                len(test_y),\n",
        "                train_y.ndim,\n",
        "                test_set.shape,\n",
        "                test_y.shape,\n",
        "                test_y.dtype\n",
        "        )\n",
        "    )\n",
        "    \n",
        "print_structures()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set             \n",
            "\tcount: 404             \n",
            "\tdimensions: 2             \n",
            "\tshape: (404, 13)             \n",
            "\tdata type: float64             \n",
            "\ttrain shape: (404,) \n",
            "\n",
            " testing set             \n",
            "\tcount: 102             \n",
            "\tdimensions: 1             \n",
            "\tshape: (102, 13)             \n",
            "\ttest shape: (102,)             \n",
            "\tdata type: float64 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvlfh2c991N1",
        "colab_type": "text"
      },
      "source": [
        "b. Construct a suitable testing set, training set, and validation set for this data. Submit code to create these datasets but do not include the datasets themselves.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avAVaaZeJM52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create Dataframes for the training and testing sets\n",
        "training_set = pd.DataFrame(train_set)\n",
        "training_set['targets']= train_y\n",
        "\n",
        "testing_set = pd.DataFrame(test_set)\n",
        "testing_set['targets']= test_y\n",
        "\n",
        "# Reindex to make sure spliting into training and validation set is random\n",
        "training_set = training_set.reindex(\n",
        "    np.random.permutation(training_set.index))\n",
        "\n",
        "# Training data spit into a training set and a validation set with an 80 - 20 split\n",
        "validation_set = training_set.tail(81)\n",
        "training_set = training_set.head(323)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihJKWN5uOaD7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "c. Create one new synthetic feature that could be useful for machine learning in this domain. Explain what it is and why it might be useful, and submit code to add it to the dataset.\n",
        "\n",
        "I couldn't figure out how to see the labels for the data. (.describe() only provided integers) I found the data labels at this link.\n",
        "http://rasbt.github.io/mlxtend/user_guide/data/boston_housing_data/\n",
        "\n",
        "\n",
        "This new synthetic feature titled Student_Opportunities multiplies together the % lower status of the population and the pupil-teacher ratio by town. This number can be used to estimate how much attention students are able to receive at home and at school for learning in a given area."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twMoPdXlOfVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_synthetic(data_frame):\n",
        "  data_frame[\"Student_Opportunities\"] = data_frame[12] * data_frame[10]\n",
        "  return data_frame\n",
        "\n",
        "validation_set = new_synthetic(validation_set)\n",
        "training_set = new_synthetic(training_set)\n",
        "testing_set = new_synthetic(testing_set)\n",
        "\n",
        "#testing_set.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}