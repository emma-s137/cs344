{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seedling_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emma-s137/cs344/blob/master/project/seedling_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akJ8fvsfGVdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDLXrqcNGlU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QITWh1N5GoqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixiXyagGy7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hyJ4Rb5HMwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the stackoverflow data set locally.\n",
        "!kaggle datasets download -d vbookshelf/v2-plant-seedlings-dataset\n",
        "!ls -l "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FgC4GlvHZQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q v2-plant-seedlings-dataset.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51-vMVZuGVhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import imageio\n",
        "import skimage\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jt5_ZgMsMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of samples we will have in each class.\n",
        "SAMPLE_SIZE = 250\n",
        "\n",
        "# The images will all be resized to this size.\n",
        "IMAGE_SIZE = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3euOaNGMtUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('nonsegmentedv2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vej2Dy3NKYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new directory to store all available images\n",
        "all_images_dir = 'all_images_dir'\n",
        "os.mkdir(all_images_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj3KyjctOG8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code copies all images from their seperate folders into the same \n",
        "# folder called all_images_dir.\n",
        "\n",
        "\n",
        "folder_list = os.listdir('nonsegmentedv2')\n",
        "\n",
        "for folder in folder_list:\n",
        "    \n",
        "    # create a path to the folder\n",
        "    path = 'nonsegmentedv2/' + str(folder)\n",
        "\n",
        "    # create a list of all files in the folder\n",
        "    file_list = os.listdir(path)\n",
        "\n",
        "    # move the 0 images to all_images_dir\n",
        "    for fname in file_list:\n",
        "\n",
        "        # source path to image\n",
        "        src = os.path.join(path, fname)\n",
        "        \n",
        "        # Change the file name because many images have the same file name.\n",
        "        # Add the folder name to the existing file name.\n",
        "        new_fname = str(folder) + '_' + fname\n",
        "        \n",
        "        # destination path to image\n",
        "        dst = os.path.join(all_images_dir, new_fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJo_Y6DuOqh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check how many images are in all_images_dir.\n",
        "# Should be 5539.\n",
        "\n",
        "len(os.listdir('all_images_dir'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEo3mU4FO5Un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a list of all images in the all_images_dir folder.\n",
        "image_list = os.listdir('all_images_dir')\n",
        "\n",
        "# Create the dataframe.\n",
        "df_data = pd.DataFrame(image_list, columns=['image_id'])\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEq1296iPG0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Each file name has this format:\n",
        "# Loose Silky-bent_377.png\n",
        "\n",
        "# This function will extract the class name from the file name of each image.\n",
        "def extract_target(x):\n",
        "    # split into a list\n",
        "    a = x.split('_')\n",
        "    # the target is the first index in the list\n",
        "    target = a[0]\n",
        "    \n",
        "    return target\n",
        "\n",
        "\n",
        "# create a new column called 'target'\n",
        "df_data['target'] = df_data['image_id'].apply(extract_target)\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgetRATkPNKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GizGAjm5dI_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What is the class distribution?\n",
        "\n",
        "df_data['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msgrl0JexgBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a list of classes\n",
        "target_list = os.listdir('nonsegmentedv2')\n",
        "\n",
        "for target in target_list:\n",
        "\n",
        "    # Filter out a target and take a random sample\n",
        "    df = df_data[df_data['target'] == target].sample(SAMPLE_SIZE, random_state=101)\n",
        "    \n",
        "    # if it's the first item in the list\n",
        "    if target == target_list[0]:\n",
        "        df_sample = df\n",
        "    else:\n",
        "        # Concat the dataframes\n",
        "        df_sample = pd.concat([df_sample, df], axis=0).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI9WSGtsxoiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the balanced classes.\n",
        "\n",
        "df_sample['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHGQIk5SdYnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_test_split\n",
        "\n",
        "# stratify=y creates a balanced validation set.\n",
        "y = df_sample['target']\n",
        "\n",
        "df_train, df_val = train_test_split(df_sample, test_size=0.10, random_state=101, stratify=y)\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXKRPL4Sx40e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set class distribution\n",
        "\n",
        "df_train['target'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkqxfKSfyNf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Val set class distribution\n",
        "\n",
        "df_val['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uywHFyLNyQ0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_list = os.listdir('nonsegmentedv2')\n",
        "\n",
        "folder_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSVVEY19ytoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new directory\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "\n",
        "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
        "\n",
        "# now we create 2 folders inside 'base_dir':\n",
        "\n",
        "# create a path to 'base_dir' to which we will join the names of the new folders\n",
        "# train_dir\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "\n",
        "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
        "\n",
        "# create new folders inside train_dir\n",
        "\n",
        "for folder in folder_list:\n",
        "    \n",
        "    folder = os.path.join(train_dir, str(folder))\n",
        "    os.mkdir(folder)\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "\n",
        "for folder in folder_list:\n",
        "    \n",
        "    folder = os.path.join(val_dir, str(folder))\n",
        "    os.mkdir(folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXsoLJFcyYwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check that the folders have been created\n",
        "\n",
        "os.listdir('base_dir/train_dir')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgBsb41Py70X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the id as the index in df_data\n",
        "df_data.set_index('image_id', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lylazBy-Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5JURd3-zHrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a list of train and val images\n",
        "train_list = list(df_train['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    folder = df_data.loc[image,'target']\n",
        "    \n",
        "    \n",
        "    # source path to image\n",
        "    src = os.path.join(all_images_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(train_dir, folder, fname)\n",
        "    \n",
        "    # resize the image and save it at the new location\n",
        "    image = cv2.imread(src)\n",
        "    image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    # save the image at the destination\n",
        "    cv2.imwrite(dst, image)\n",
        "        \n",
        "    \n",
        "\n",
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    folder = df_data.loc[image,'target']\n",
        "    \n",
        "\n",
        "    # source path to image\n",
        "    src = os.path.join(all_images_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(val_dir, folder, fname)\n",
        "\n",
        "    # resize the image and save it at the new location\n",
        "    image = cv2.imread(src)\n",
        "    image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    # save the image at the destination\n",
        "    cv2.imwrite(dst, image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i86KItBzXsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_list = os.listdir('base_dir/train_dir')\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "# loop through each folder\n",
        "for folder in folder_list:\n",
        "    # set the path to a folder\n",
        "    path = 'base_dir/train_dir/' + str(folder)\n",
        "    # get a list of images in that folder\n",
        "    images_list = os.listdir(path)\n",
        "    # get the length of the list\n",
        "    num_images = len(images_list)\n",
        "    \n",
        "    total_images = total_images + num_images\n",
        "    # print the result\n",
        "    print(str(folder) + ':' + ' ' + str(num_images))\n",
        "    \n",
        "print('\\n')\n",
        "# print the total number of images available\n",
        "print('Total Images: ', total_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_kzwEfYzhNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a list of image folders\n",
        "folder_list = os.listdir('base_dir/val_dir')\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "# loop through each folder\n",
        "for folder in folder_list:\n",
        "    # set the path to a folder\n",
        "    path = 'base_dir/val_dir/' + str(folder)\n",
        "    # get a list of images in that folder\n",
        "    images_list = os.listdir(path)\n",
        "    # get the length of the list\n",
        "    num_images = len(images_list)\n",
        "    \n",
        "    total_images = total_images + num_images\n",
        "    # print the result\n",
        "    print(str(folder) + ':' + ' ' + str(num_images))\n",
        "    \n",
        "print('\\n')\n",
        "# print the total number of images available\n",
        "print('Total Images: ', total_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGS2zn9ezkYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pnqs5L1ztZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQy09N9JZHLZ",
        "colab_type": "text"
      },
      "source": [
        "Basic neural network Model similar to the one devoleped for homework04."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQorHSrEdtB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "\n",
        "model_basic = Sequential()\n",
        "model_basic.add(Conv2D(32, kernel_size, activation = 'relu', \n",
        "                 input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "\n",
        "model_basic.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model_basic.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_basic.add(Dropout(0.25))\n",
        "\n",
        "model_basic.add(Conv2D(128, kernel_size, activation ='relu'))\n",
        "model_basic.add(MaxPooling2D(pool_size = pool_size))\n",
        "model_basic.add(Dropout(0.25))\n",
        "\n",
        "model_basic.add(Flatten())\n",
        "model_basic.add(Dense(64, activation = \"relu\"))\n",
        "model_basic.add(Dense(12, activation = \"softmax\"))\n",
        "\n",
        "model_basic.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EY-cUl1lLlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_basic.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adagrad',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model_basic.fit(train_gen,\n",
        "         epochs=25,\n",
        "         validation_data=val_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DKGrVVRLWa8",
        "colab_type": "text"
      },
      "source": [
        "Model uses Alex Net architecture\n",
        "Found at https://www.mydatahack.com/building-alexnet-with-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjJwObm40qjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1) Importing dependency\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        " Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),\\\n",
        " strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(12, activation = \"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adagrad',\\\n",
        " metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0ZNxPXZLsur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (5) Train\n",
        "model.fit(train_gen, epochs=25, verbose=1, shuffle=True, validation_data=val_gen )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}