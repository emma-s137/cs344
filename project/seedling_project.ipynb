{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seedling_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emma-s137/cs344/blob/master/project/seedling_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2-Q0wQt5TE_",
        "colab_type": "text"
      },
      "source": [
        "Data pre-processing modeled from https://www.kaggle.com/vbookshelf/a-simple-keras-solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akJ8fvsfGVdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDLXrqcNGlU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8551174d-4525-4671-d8d9-a9bafcf197e3"
      },
      "source": [
        "# Let's make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 67 May 20 20:19 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QITWh1N5GoqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixiXyagGy7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hyJ4Rb5HMwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cebe0fce-63d9-4bd7-e566-7900433dd4e4"
      },
      "source": [
        "# Copy the stackoverflow data set locally.\n",
        "!kaggle datasets download -d vbookshelf/v2-plant-seedlings-dataset\n",
        "!ls -l "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading v2-plant-seedlings-dataset.zip to /content\n",
            "100% 3.18G/3.19G [00:37<00:00, 72.8MB/s]\n",
            "100% 3.19G/3.19G [00:37<00:00, 90.5MB/s]\n",
            "total 3347024\n",
            "-rw-r--r-- 1 root root         67 May 20 20:19 kaggle.json\n",
            "drwxr-xr-x 1 root root       4096 May 13 16:29 sample_data\n",
            "-rw-r--r-- 1 root root 3427338216 May 20 20:20 v2-plant-seedlings-dataset.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FgC4GlvHZQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q v2-plant-seedlings-dataset.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51-vMVZuGVhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import imageio\n",
        "import skimage\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jt5_ZgMsMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of samples we will have in each class.\n",
        "SAMPLE_SIZE = 250\n",
        "\n",
        "# The images will all be resized to this size.\n",
        "IMAGE_SIZE = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3euOaNGMtUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5b17c542-7663-4d33-bcce-d4ece62546c4"
      },
      "source": [
        "os.listdir('nonsegmentedv2')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Maize',\n",
              " 'Black-grass',\n",
              " 'Scentless Mayweed',\n",
              " 'Sugar beet',\n",
              " 'Fat Hen',\n",
              " 'Loose Silky-bent',\n",
              " 'ShepherdтАЩs Purse',\n",
              " 'Cleavers',\n",
              " 'Common wheat',\n",
              " 'Small-flowered Cranesbill',\n",
              " 'Common Chickweed',\n",
              " 'Charlock']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vej2Dy3NKYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new directory to store all available images\n",
        "all_images_dir = 'all_images_dir'\n",
        "os.mkdir(all_images_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj3KyjctOG8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code copies all images from their seperate folders into the same \n",
        "# folder called all_images_dir.\n",
        "\n",
        "\n",
        "folder_list = os.listdir('nonsegmentedv2')\n",
        "\n",
        "for folder in folder_list:\n",
        "    \n",
        "    # create a path to the folder\n",
        "    path = 'nonsegmentedv2/' + str(folder)\n",
        "\n",
        "    # create a list of all files in the folder\n",
        "    file_list = os.listdir(path)\n",
        "\n",
        "    # move the 0 images to all_images_dir\n",
        "    for fname in file_list:\n",
        "\n",
        "        # source path to image\n",
        "        src = os.path.join(path, fname)\n",
        "        \n",
        "        # Change the file name because many images have the same file name.\n",
        "        # Add the folder name to the existing file name.\n",
        "        new_fname = str(folder) + '_' + fname\n",
        "        \n",
        "        # destination path to image\n",
        "        dst = os.path.join(all_images_dir, new_fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJo_Y6DuOqh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "808e32f9-83c0-4c77-8051-7c3cdc15133a"
      },
      "source": [
        "# Check how many images are in all_images_dir.\n",
        "# Should be 5539.\n",
        "\n",
        "len(os.listdir('all_images_dir'))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5539"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEo3mU4FO5Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "369da9c9-b573-44d3-a5bc-b66ce66a32aa"
      },
      "source": [
        "# Get a list of all images in the all_images_dir folder.\n",
        "image_list = os.listdir('all_images_dir')\n",
        "\n",
        "# Create the dataframe.\n",
        "df_data = pd.DataFrame(image_list, columns=['image_id'])\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Common Chickweed_359.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sugar beet_177.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fat Hen_304.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Small-flowered Cranesbill_57.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Common wheat_128.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           image_id\n",
              "0          Common Chickweed_359.png\n",
              "1                Sugar beet_177.png\n",
              "2                   Fat Hen_304.png\n",
              "3  Small-flowered Cranesbill_57.png\n",
              "4              Common wheat_128.png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEq1296iPG0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "182d5e6a-4945-4231-d3ae-53894b97eb6b"
      },
      "source": [
        "# Each file name has this format:\n",
        "# Loose Silky-bent_377.png\n",
        "\n",
        "# This function will extract the class name from the file name of each image.\n",
        "def extract_target(x):\n",
        "    # split into a list\n",
        "    a = x.split('_')\n",
        "    # the target is the first index in the list\n",
        "    target = a[0]\n",
        "    \n",
        "    return target\n",
        "\n",
        "\n",
        "# create a new column called 'target'\n",
        "df_data['target'] = df_data['image_id'].apply(extract_target)\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Common Chickweed_359.png</td>\n",
              "      <td>Common Chickweed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sugar beet_177.png</td>\n",
              "      <td>Sugar beet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fat Hen_304.png</td>\n",
              "      <td>Fat Hen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Small-flowered Cranesbill_57.png</td>\n",
              "      <td>Small-flowered Cranesbill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Common wheat_128.png</td>\n",
              "      <td>Common wheat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           image_id                     target\n",
              "0          Common Chickweed_359.png           Common Chickweed\n",
              "1                Sugar beet_177.png                 Sugar beet\n",
              "2                   Fat Hen_304.png                    Fat Hen\n",
              "3  Small-flowered Cranesbill_57.png  Small-flowered Cranesbill\n",
              "4              Common wheat_128.png               Common wheat"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgetRATkPNKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8d60cd1-32d1-4af7-ead0-cdd845e2abb2"
      },
      "source": [
        "df_data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5539, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GizGAjm5dI_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8c2affc5-63a6-4e91-c945-a14975b11398"
      },
      "source": [
        "# What is the class distribution?\n",
        "\n",
        "df_data['target'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loose Silky-bent             762\n",
              "Common Chickweed             713\n",
              "Scentless Mayweed            607\n",
              "Small-flowered Cranesbill    576\n",
              "Fat Hen                      538\n",
              "Sugar beet                   463\n",
              "Charlock                     452\n",
              "Cleavers                     335\n",
              "Black-grass                  309\n",
              "ShepherdтАЩs Purse           274\n",
              "Maize                        257\n",
              "Common wheat                 253\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msgrl0JexgBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a list of classes\n",
        "target_list = os.listdir('nonsegmentedv2')\n",
        "\n",
        "for target in target_list:\n",
        "\n",
        "    # Filter out a target and take a random sample\n",
        "    df = df_data[df_data['target'] == target].sample(SAMPLE_SIZE, random_state=101)\n",
        "    \n",
        "    # if it's the first item in the list\n",
        "    if target == target_list[0]:\n",
        "        df_sample = df\n",
        "    else:\n",
        "        # Concat the dataframes\n",
        "        df_sample = pd.concat([df_sample, df], axis=0).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI9WSGtsxoiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cfcdedd5-fee2-4097-e4cb-348e17bbb252"
      },
      "source": [
        "# Display the balanced classes.\n",
        "\n",
        "df_sample['target'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sugar beet                   250\n",
              "Fat Hen                      250\n",
              "Small-flowered Cranesbill    250\n",
              "Cleavers                     250\n",
              "Loose Silky-bent             250\n",
              "Maize                        250\n",
              "Scentless Mayweed            250\n",
              "Black-grass                  250\n",
              "Common Chickweed             250\n",
              "Common wheat                 250\n",
              "Charlock                     250\n",
              "ShepherdтАЩs Purse           250\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHGQIk5SdYnH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1d84e269-78ac-4420-b09f-6e5b977ef12a"
      },
      "source": [
        "# train_test_split\n",
        "\n",
        "# stratify=y creates a balanced validation set.\n",
        "y = df_sample['target']\n",
        "\n",
        "df_train, df_val = train_test_split(df_sample, test_size=0.10, random_state=101, stratify=y)\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2700, 2)\n",
            "(300, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXKRPL4Sx40e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "89d0acb7-cc16-4c1a-e5ff-407ad7180207"
      },
      "source": [
        "# Train set class distribution\n",
        "\n",
        "df_train['target'].value_counts()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sugar beet                   225\n",
              "Fat Hen                      225\n",
              "Small-flowered Cranesbill    225\n",
              "Cleavers                     225\n",
              "Loose Silky-bent             225\n",
              "Maize                        225\n",
              "Scentless Mayweed            225\n",
              "Black-grass                  225\n",
              "Common Chickweed             225\n",
              "Common wheat                 225\n",
              "Charlock                     225\n",
              "ShepherdтАЩs Purse           225\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkqxfKSfyNf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "08eddbbd-b19f-4e63-d967-3cd8a7bd1362"
      },
      "source": [
        "# Val set class distribution\n",
        "\n",
        "df_val['target'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Black-grass                  25\n",
              "Loose Silky-bent             25\n",
              "Charlock                     25\n",
              "Common wheat                 25\n",
              "Fat Hen                      25\n",
              "Cleavers                     25\n",
              "Maize                        25\n",
              "Scentless Mayweed            25\n",
              "ShepherdтАЩs Purse           25\n",
              "Sugar beet                   25\n",
              "Small-flowered Cranesbill    25\n",
              "Common Chickweed             25\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uywHFyLNyQ0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e90ade97-1af4-43ad-a1b9-eb5e7d8660b5"
      },
      "source": [
        "folder_list = os.listdir('nonsegmentedv2')\n",
        "\n",
        "folder_list"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Maize',\n",
              " 'Black-grass',\n",
              " 'Scentless Mayweed',\n",
              " 'Sugar beet',\n",
              " 'Fat Hen',\n",
              " 'Loose Silky-bent',\n",
              " 'ShepherdтАЩs Purse',\n",
              " 'Cleavers',\n",
              " 'Common wheat',\n",
              " 'Small-flowered Cranesbill',\n",
              " 'Common Chickweed',\n",
              " 'Charlock']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSVVEY19ytoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new directory\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "\n",
        "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
        "\n",
        "# now we create 2 folders inside 'base_dir':\n",
        "\n",
        "# create a path to 'base_dir' to which we will join the names of the new folders\n",
        "# train_dir\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "\n",
        "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
        "\n",
        "# create new folders inside train_dir\n",
        "\n",
        "for folder in folder_list:\n",
        "    \n",
        "    folder = os.path.join(train_dir, str(folder))\n",
        "    os.mkdir(folder)\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "\n",
        "for folder in folder_list:\n",
        "    \n",
        "    folder = os.path.join(val_dir, str(folder))\n",
        "    os.mkdir(folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXsoLJFcyYwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0f55cc7e-95fd-4a83-d694-767b89d82274"
      },
      "source": [
        "# check that the folders have been created\n",
        "\n",
        "os.listdir('base_dir/train_dir')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Maize',\n",
              " 'Black-grass',\n",
              " 'Scentless Mayweed',\n",
              " 'Sugar beet',\n",
              " 'Fat Hen',\n",
              " 'Loose Silky-bent',\n",
              " 'ShepherdтАЩs Purse',\n",
              " 'Cleavers',\n",
              " 'Common wheat',\n",
              " 'Small-flowered Cranesbill',\n",
              " 'Common Chickweed',\n",
              " 'Charlock']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgBsb41Py70X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the id as the index in df_data\n",
        "df_data.set_index('image_id', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lylazBy-Ye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d78a175a-7426-4f03-abca-59e123385fa0"
      },
      "source": [
        "df_data.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Common Chickweed_359.png</th>\n",
              "      <td>Common Chickweed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sugar beet_177.png</th>\n",
              "      <td>Sugar beet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fat Hen_304.png</th>\n",
              "      <td>Fat Hen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Small-flowered Cranesbill_57.png</th>\n",
              "      <td>Small-flowered Cranesbill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Common wheat_128.png</th>\n",
              "      <td>Common wheat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     target\n",
              "image_id                                                   \n",
              "Common Chickweed_359.png                   Common Chickweed\n",
              "Sugar beet_177.png                               Sugar beet\n",
              "Fat Hen_304.png                                     Fat Hen\n",
              "Small-flowered Cranesbill_57.png  Small-flowered Cranesbill\n",
              "Common wheat_128.png                           Common wheat"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5JURd3-zHrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a list of train and val images\n",
        "train_list = list(df_train['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    folder = df_data.loc[image,'target']\n",
        "    \n",
        "    \n",
        "    # source path to image\n",
        "    src = os.path.join(all_images_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(train_dir, folder, fname)\n",
        "    \n",
        "    # resize the image and save it at the new location\n",
        "    image = cv2.imread(src)\n",
        "    image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    # save the image at the destination\n",
        "    cv2.imwrite(dst, image)\n",
        "        \n",
        "    \n",
        "\n",
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    folder = df_data.loc[image,'target']\n",
        "    \n",
        "\n",
        "    # source path to image\n",
        "    src = os.path.join(all_images_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(val_dir, folder, fname)\n",
        "\n",
        "    # resize the image and save it at the new location\n",
        "    image = cv2.imread(src)\n",
        "    image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    # save the image at the destination\n",
        "    cv2.imwrite(dst, image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i86KItBzXsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b43c2bc0-0044-405b-c670-edba8ed17497"
      },
      "source": [
        "folder_list = os.listdir('base_dir/train_dir')\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "# loop through each folder\n",
        "for folder in folder_list:\n",
        "    # set the path to a folder\n",
        "    path = 'base_dir/train_dir/' + str(folder)\n",
        "    # get a list of images in that folder\n",
        "    images_list = os.listdir(path)\n",
        "    # get the length of the list\n",
        "    num_images = len(images_list)\n",
        "    \n",
        "    total_images = total_images + num_images\n",
        "    # print the result\n",
        "    print(str(folder) + ':' + ' ' + str(num_images))\n",
        "    \n",
        "print('\\n')\n",
        "# print the total number of images available\n",
        "print('Total Images: ', total_images)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maize: 225\n",
            "Black-grass: 225\n",
            "Scentless Mayweed: 225\n",
            "Sugar beet: 225\n",
            "Fat Hen: 225\n",
            "Loose Silky-bent: 225\n",
            "ShepherdтАЩs Purse: 225\n",
            "Cleavers: 225\n",
            "Common wheat: 225\n",
            "Small-flowered Cranesbill: 225\n",
            "Common Chickweed: 225\n",
            "Charlock: 225\n",
            "\n",
            "\n",
            "Total Images:  2700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_kzwEfYzhNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c824504f-921b-44ab-d0d3-b4106b5c5c04"
      },
      "source": [
        "# get a list of image folders\n",
        "folder_list = os.listdir('base_dir/val_dir')\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "# loop through each folder\n",
        "for folder in folder_list:\n",
        "    # set the path to a folder\n",
        "    path = 'base_dir/val_dir/' + str(folder)\n",
        "    # get a list of images in that folder\n",
        "    images_list = os.listdir(path)\n",
        "    # get the length of the list\n",
        "    num_images = len(images_list)\n",
        "    \n",
        "    total_images = total_images + num_images\n",
        "    # print the result\n",
        "    print(str(folder) + ':' + ' ' + str(num_images))\n",
        "    \n",
        "print('\\n')\n",
        "# print the total number of images available\n",
        "print('Total Images: ', total_images)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maize: 25\n",
            "Black-grass: 25\n",
            "Scentless Mayweed: 25\n",
            "Sugar beet: 25\n",
            "Fat Hen: 25\n",
            "Loose Silky-bent: 25\n",
            "ShepherdтАЩs Purse: 25\n",
            "Cleavers: 25\n",
            "Common wheat: 25\n",
            "Small-flowered Cranesbill: 25\n",
            "Common Chickweed: 25\n",
            "Charlock: 25\n",
            "\n",
            "\n",
            "Total Images:  300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGS2zn9ezkYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pnqs5L1ztZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f08e3363-f3b1-4504-eebe-7e553cb8929b"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2700 images belonging to 12 classes.\n",
            "Found 300 images belonging to 12 classes.\n",
            "Found 300 images belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQy09N9JZHLZ",
        "colab_type": "text"
      },
      "source": [
        "Basic neural network Model similar to the one devoleped for homework04."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQorHSrEdtB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "d1c32b4b-f583-4d64-9d55-3ae9fd13cff0"
      },
      "source": [
        "\n",
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "\n",
        "model_basic = Sequential()\n",
        "model_basic.add(Conv2D(32, kernel_size, activation = 'relu', \n",
        "                 input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "\n",
        "model_basic.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model_basic.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_basic.add(Dropout(0.25))\n",
        "\n",
        "model_basic.add(Conv2D(128, kernel_size, activation ='relu'))\n",
        "model_basic.add(MaxPooling2D(pool_size = pool_size))\n",
        "model_basic.add(Dropout(0.25))\n",
        "\n",
        "model_basic.add(Flatten())\n",
        "model_basic.add(Dense(64, activation = \"relu\"))\n",
        "model_basic.add(Dense(12, activation = \"softmax\"))\n",
        "\n",
        "model_basic.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 220, 220, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 110, 110, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 108, 108, 128)     36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 54, 54, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 373248)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                23887936  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 23,935,852\n",
            "Trainable params: 23,935,852\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EY-cUl1lLlU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "aca5de1f-518b-4d57-ef69-daffc7950c93"
      },
      "source": [
        "model_basic.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adagrad',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model_basic.fit(train_gen,\n",
        "         epochs=10,\n",
        "         validation_data=val_gen)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "270/270 [==============================] - 537s 2s/step - loss: 2.3542 - accuracy: 0.1867 - val_loss: 2.1223 - val_accuracy: 0.2300\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 537s 2s/step - loss: 1.8501 - accuracy: 0.3219 - val_loss: 1.8555 - val_accuracy: 0.3100\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 534s 2s/step - loss: 1.5666 - accuracy: 0.4600 - val_loss: 1.6594 - val_accuracy: 0.3667\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 535s 2s/step - loss: 1.3613 - accuracy: 0.5411 - val_loss: 1.5268 - val_accuracy: 0.4567\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 537s 2s/step - loss: 1.2256 - accuracy: 0.6030 - val_loss: 1.4957 - val_accuracy: 0.4467\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 537s 2s/step - loss: 1.1249 - accuracy: 0.6311 - val_loss: 1.4245 - val_accuracy: 0.5033\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 545s 2s/step - loss: 1.0423 - accuracy: 0.6663 - val_loss: 1.3759 - val_accuracy: 0.5233\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 540s 2s/step - loss: 0.9589 - accuracy: 0.6881 - val_loss: 1.3560 - val_accuracy: 0.5333\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 539s 2s/step - loss: 0.8920 - accuracy: 0.7259 - val_loss: 1.2820 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 538s 2s/step - loss: 0.8352 - accuracy: 0.7396 - val_loss: 1.2676 - val_accuracy: 0.5833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e4cc9c080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DKGrVVRLWa8",
        "colab_type": "text"
      },
      "source": [
        "Model uses Alex Net architecture\n",
        "Found at https://www.mydatahack.com/building-alexnet-with-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjJwObm40qjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da232b25-aa66-4440-abd5-6307c01eeb16"
      },
      "source": [
        "# (1) Importing dependency\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        " Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),\\\n",
        " strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(12, activation = \"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adagrad',\\\n",
        " metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 12)                12012     \n",
            "=================================================================\n",
            "Total params: 28,091,764\n",
            "Trainable params: 28,070,628\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0ZNxPXZLsur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "af866195-99f2-4a13-f509-1fd1df092017"
      },
      "source": [
        "# (5) Train\n",
        "model.fit(train_gen, epochs=10, verbose=1, shuffle=True, validation_data=val_gen )"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "270/270 [==============================] - 451s 2s/step - loss: 2.2492 - accuracy: 0.2185 - val_loss: 1.5627 - val_accuracy: 0.2167\n",
            "Epoch 2/10\n",
            "270/270 [==============================] - 453s 2s/step - loss: 2.1246 - accuracy: 0.2552 - val_loss: 4.2817 - val_accuracy: 0.2300\n",
            "Epoch 3/10\n",
            "270/270 [==============================] - 449s 2s/step - loss: 2.0759 - accuracy: 0.2641 - val_loss: 3.4364 - val_accuracy: 0.1767\n",
            "Epoch 4/10\n",
            "270/270 [==============================] - 449s 2s/step - loss: 1.9910 - accuracy: 0.3015 - val_loss: 3.0909 - val_accuracy: 0.1967\n",
            "Epoch 5/10\n",
            "270/270 [==============================] - 446s 2s/step - loss: 1.9735 - accuracy: 0.2989 - val_loss: 1.5700 - val_accuracy: 0.2633\n",
            "Epoch 6/10\n",
            "270/270 [==============================] - 449s 2s/step - loss: 1.8365 - accuracy: 0.3426 - val_loss: 1.6589 - val_accuracy: 0.3700\n",
            "Epoch 7/10\n",
            "270/270 [==============================] - 450s 2s/step - loss: 1.8029 - accuracy: 0.3663 - val_loss: 1.5254 - val_accuracy: 0.3633\n",
            "Epoch 8/10\n",
            "270/270 [==============================] - 453s 2s/step - loss: 1.7045 - accuracy: 0.3893 - val_loss: 2.0123 - val_accuracy: 0.3500\n",
            "Epoch 9/10\n",
            "270/270 [==============================] - 450s 2s/step - loss: 1.6888 - accuracy: 0.4048 - val_loss: 1.9406 - val_accuracy: 0.2833\n",
            "Epoch 10/10\n",
            "270/270 [==============================] - 448s 2s/step - loss: 1.6959 - accuracy: 0.3959 - val_loss: 1.2602 - val_accuracy: 0.5333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1e44231e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmQuWKAW3sHW",
        "colab_type": "text"
      },
      "source": [
        "Overall, it looks as though the more simple basic architecture has a better validation accuracy of 0.58, as compared with 0.53. However, we can see at 10 epochs the model has slowed down severely in its progress, and the additional epochs would lead to more overfitting as opposed to additional accuracy.\n",
        "\n",
        "In contrast, the Alex Net architecture seems to be just getting started. We observe virtually no overfitting as the validation accuracy is better then the accuracy for the trainning set. In addition, the model was only trained for 10 epochs for time purposes, but the model seemed to still be advancing in the right direction when it was stopped. One article, I read discussing the architecture said that the model normally trained for 5 to 6 days. Although, the limited training seems not to bad considering AlexNet is designed to classify with up to 1,000 different categories and much larger data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9B8eFYMtd2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r test_images/\n",
        "!mkdir test_images\n",
        "!mkdir test_images/Acorn\n",
        "!mkdir test_images/Fat\\ Hen\n",
        "!mkdir test_images/Maize\n",
        "\n",
        "!cp base_dir/val_dir/Charlock/Charlock_32.png test_images/Acorn/Acorn_32.png\n",
        "!cp base_dir/val_dir/Fat\\ Hen/'Fat Hen_238.png' test_images/Fat\\ Hen/'Fat Hen_238.png'\n",
        "!cp base_dir/val_dir/Maize/Maize_255.png test_images/Maize/Maize_255.png\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgzeID1wx6F_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0bc24476-98f2-415f-eed7-2d670e3e9041"
      },
      "source": [
        "# This is how to check what index keras has internally assigned to each class. \n",
        "test_gen.class_indices"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Black-grass': 0,\n",
              " 'Charlock': 1,\n",
              " 'Cleavers': 2,\n",
              " 'Common Chickweed': 3,\n",
              " 'Common wheat': 4,\n",
              " 'Fat Hen': 5,\n",
              " 'Loose Silky-bent': 6,\n",
              " 'Maize': 7,\n",
              " 'Scentless Mayweed': 8,\n",
              " 'ShepherdтАЩs Purse': 9,\n",
              " 'Small-flowered Cranesbill': 10,\n",
              " 'Sugar beet': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOxfc4S11BOY",
        "colab_type": "text"
      },
      "source": [
        "From this we can see that the inputs do fit with the same internal indices\n",
        "when the model predicts what the picture is. The basic model correctly identifies Charlock, Maize and 'Fat Hen'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmXk0pZYjuqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0d165456-d83c-4a81-ff59-1bbad12e368d"
      },
      "source": [
        "imgPath = 'test_images/'\n",
        "!ls test_images/\n",
        "\n",
        "img = datagen.flow_from_directory(imgPath,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        class_mode='categorical'\n",
        "                                  )\n",
        "\n",
        "model_basic.predict_classes(img)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Acorn\t'Fat Hen'   Maize\n",
            "Found 3 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 7, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    }
  ]
}