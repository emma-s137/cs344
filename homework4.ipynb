{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNe9l0EllMejYvaQgC3SfRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emma-s137/cs344/blob/master/homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMFOXG5k8YJx",
        "colab_type": "text"
      },
      "source": [
        "1. Speculate on whether you believe that so-called “deep” neural networks are destined to be another bust just as perceptrons and expert systems were in the past, or whether they really are a breakthrough that will be used for years into the future. Please give a two-to-three-paragraph answer, including examples to back up your argument.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNEZrux48iwV",
        "colab_type": "text"
      },
      "source": [
        "I believe that the \"deep\" neural networks will not just be another bust as peceptrons or expert systems. One reason for this is because the focus a \"deep\" neural network is more data. In the digital, we are know living in these machine learning models will become easier to implement, as more and more data is collected. There are people in the the transhumanist movements that hope to completely monitor the activity of their own body (individual mentioned in Mark O'Connell's book To Be A Machine). Already apple watches and advancements towards smart homes (such as fridges and fish tanks) have given us more acess to data then ever before. A neural network that then learns from data seems to be an optimal direction for AI.\n",
        "\n",
        "The failure with expert systems was the idea that the world behaves on the basis of rules. The idea that these rules can be hard coded, and that by logical reasoning an AI can discern the answer to a question. However, in many complex problems we see that certain rules will take precendence over others, and sometimes rules can be completely thrown out. It was also difficut when a new body of knowledge was discovered. The expert system would then need to be completely updated. However, with neural networks the answer is just to feed in more data. One specific problem, that proved very difficult for the rigidness of expert systems, but was more successful with neural nets was voice recognition.\n",
        "\n",
        "The perceptron by itself proved to be to simple for solving more nuanced problems with many different parameters and patterns that could be picked up on. The perceptron was limited was a linear classified, but layering of these nodes alllowed for more complex problems to be solved.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KdUXUg08jJq",
        "colab_type": "text"
      },
      "source": [
        "2. Hand-compute a single, complete back-propagation cycle. Use the example network from class and compute the updated weight values for the first gradient descent iteration for the XOR example, i.e., [1, 1] → 0. Use the same initial weights we used in the class example but assume the identity function as the activation function (f(x) = x).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3CQwkwO8l9v",
        "colab_type": "text"
      },
      "source": [
        "See image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNGXJqJ883AG",
        "colab_type": "text"
      },
      "source": [
        "3. Build a Keras-based ConvNet for Keras’s Fashion MNIST dataset (fashion_mnist). Experiment with different network architectures, submit your most performant network, and report the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkt6FDxygfsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# References\n",
        "# https://keras.io/layers/convolutional/\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/\n",
        "# https://victorzhou.com/blog/keras-neural-network-tutorial/\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Split validation and trainning set with an 80, 20 plit\n",
        "val_images = train_images[54000:]\n",
        "train_images = train_images[:54000]\n",
        "\n",
        "val_labels = train_labels[54000:]\n",
        "train_labels = train_labels[:54000]\n",
        "\n",
        "val_data = (val_images, val_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inDecswwousa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6007335a-af78-49ab-98d4-a5a496d304e7"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = Sequential()\n",
        "# Two Convolution layers that are 2D for pictures\n",
        "model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Simplify output and put into 10 different categories\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model.summary()\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 64)                589888    \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 609,354\n",
            "Trainable params: 609,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYhlBRUto9Sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "03b58b96-6494-478f-aeb0-3ca07599c2f0"
      },
      "source": [
        "#categorical_crossentropy for making groups\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adagrad',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images,\n",
        "         train_labels,\n",
        "         batch_size=64,\n",
        "         epochs=5,\n",
        "         validation_data=val_data)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/5\n",
            "54000/54000 [==============================] - 123s 2ms/step - loss: 0.4106 - accuracy: 0.8551 - val_loss: 0.3196 - val_accuracy: 0.8840\n",
            "Epoch 2/5\n",
            "54000/54000 [==============================] - 124s 2ms/step - loss: 0.2815 - accuracy: 0.8994 - val_loss: 0.2782 - val_accuracy: 0.9010\n",
            "Epoch 3/5\n",
            "54000/54000 [==============================] - 125s 2ms/step - loss: 0.2472 - accuracy: 0.9119 - val_loss: 0.2595 - val_accuracy: 0.9065\n",
            "Epoch 4/5\n",
            "54000/54000 [==============================] - 125s 2ms/step - loss: 0.2260 - accuracy: 0.9196 - val_loss: 0.2466 - val_accuracy: 0.9120\n",
            "Epoch 5/5\n",
            "54000/54000 [==============================] - 129s 2ms/step - loss: 0.2100 - accuracy: 0.9239 - val_loss: 0.2416 - val_accuracy: 0.9135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f092d7a1898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yimrfBNKsuVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3e2e5844-d11b-4094-944c-9576fc79340e"
      },
      "source": [
        "# Evaluate the model on sets\n",
        "print(model.evaluate(train_images, train_labels))\n",
        "print(model.evaluate(val_images, val_labels))\n",
        "print(model.evaluate(test_images, test_labels))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54000/54000 [==============================] - 33s 616us/step\n",
            "[0.19506046934812157, 0.9306666851043701]\n",
            "6000/6000 [==============================] - 4s 628us/step\n",
            "[0.24163730388879776, 0.9135000109672546]\n",
            "10000/10000 [==============================] - 6s 614us/step\n",
            "[0.257784378182888, 0.9065999984741211]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3DP2lBORmCW",
        "colab_type": "text"
      },
      "source": [
        " \n",
        "The trainning set has an accuracy of 93.1%,\n",
        "   the validation set is 91.3%\n",
        "   and the testing set is 90.6%.\n",
        "\n",
        "This seems to be a good model without too much overfitting."
      ]
    }
  ]
}